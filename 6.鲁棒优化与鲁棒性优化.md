\chapter{鲁棒性优化（Robustness Optimization）}
\begin{center}
    \chapterauthor{陈植，汤勤深}
\end{center}

\section{目标驱动最优化和Satisficing（Goal-Driven Optimization and Satisficing）}

\section{鲁棒性优化（Robustness Optimization）}
经济学和心理学中常用Satisficing理论来研究决策者在不确定环境下的决策过程。在Satisficing理论的假设中，决策者依据能够同时满足全部约束的可能性大小来对各决策进行排序，并选取其中最有可能同时满足全部约束的为最优决策。基于Satisficing理论，\cite{Jaillet_2016}提出如下模型
$$
\begin{array}{cll}
\max & \rho(\bm{\alpha}) \\
{\rm s.t.} & \bm{A}(\bm{z})\bm{x} \geq \bm{b}(\bm{z}) &~\forall \bm{z} \in \mathcal{U}(\bm{\alpha}) \\
& \bm{x} \in \mathcal{X} \\
& \bm{\alpha} \in \mathcal{S}. 
\end{array}
$$

一般地，对参数化不确定集合$\mathcal{U}(\bm{\alpha})$, 可行决策$\bm{x} \in \mathcal{X}$需要满足鲁棒约束
$$
\bm{A}(\bm{z})\bm{x} \geq \bm{b}(\bm{z}) ~~~\forall \bm{z} \in \mathcal{U}(\bm{\alpha}).
$$
参数$\bm{\alpha}$决定了不确定集合$\mathcal{U}(\bm{\alpha})$的大小，函数$\rho(\bm{\alpha})$则反映了决策者对这一参数的喜好程度。

最简单的，取一维参数$\alpha$，$\mathcal{S} = \mathbb{R}_+$， 和$\rho(\alpha) = \alpha$, 上述模型即变为
$$
\begin{array}{cll}
\max & \alpha \\
{\rm s.t.} & \bm{A}(\bm{z})\bm{x} \geq \bm{b}(\bm{z}) &~\forall \bm{z} \in \mathcal{U}(\alpha) \\
& \bm{x} \in \mathcal{X} \\
& \alpha \geq 0. 
\end{array}
$$
\cite{Jaillet_2016}称之为鲁棒性优化（Robustness Optimization）模型。 

从Satisficing理论出发，鲁棒性优化模型为一般鲁棒优化模型
$$
\begin{array}{cll}
\max & \bm{c}'\bm{x} \\
{\rm s.t.} & \bm{A}(\bm{z})\bm{x} \geq \bm{b}(\bm{z}) &~\forall \bm{z} \in \mathcal{U}(\Gamma) \\
& \bm{x} \in \mathcal{X}
\end{array}
$$
提供了新的解释。一般鲁棒优化模型需要决策者声明自己对不确定性的偏好，即声明不确定集合$\mathcal{U}(\Gamma)$的大小。不确定集合$\mathcal{U}(\Gamma)$的大小通常由参数$\Gamma$直接调控。例如，\cite{Bertsimas_Sim_2004price}提出的鲁棒价格$\Gamma$调控了不确定参数中有多少成分能够同时取到最坏情况。对于一些决策者而言，这并不是一件容易的事，因为他们对自己的偏好并没有清楚的认识；相反，声明自身可接受的成本（亦即$\bm{c}'\bm{x}$）也许更容易。对这样的决策者而言，求解如下鲁棒性优化模型或许更为直观
$$
\begin{array}{cll}
\max & \alpha \\
{\rm s.t.} & \bm{A}(\bm{z})\bm{x} \geq \bm{b}(\bm{z}) &~\forall \bm{z} \in \mathcal{U}(\alpha) \\
& \bm{x} \in \mathcal{X} \\
& \bm{c}'\bm{x} \leq B \\
& \alpha \geq 0. 
\end{array}
$$
在可控成本范围内（$\bm{c}'\bm{x} \leq B$），在更大的不确定集合影响下依然能满足不确定性约束的决策则更优。这样的决策标准，正好可以在Satisficing理论的框架下进行解释。


\iffalse
    \section{鲁棒随机优化（Robust Stochastic Optimization）}
    \label{RSO}
    在这一章中，我们介绍 \cite{Chen_Sim_Xiong_2019} 提出的鲁棒随机优化（Robust Stochastic Optimization, RSO）模型的统一框架。
    
    定义静态决策$\bm{w} \in \mathbb{R}^{J_w}$，连续随机变量$\bmt{z}$， 和离散随机变量$\tilde{s}$。定义只取决于离散随机变量$\tilde{s}$的动态决策$\bm{x}(s):[S] \mapsto \mathbb{R}^{J_x}$,以及同时取决于连续随机变量$\bmt{z}$和离散随机变量$\tilde{s}$的动态决策$\bm{y}(s,\bm{z}): [S] \times \mathbb{R}^{I_z} \mapsto \mathbb{R}^{J_y}$。与线性近似法则类似，对应离散随机变量的不同取值，动态决策$\bm{y}(s,\bm{z})$为连续随机变量$\bmt{z}$的不同的线性函数：
    $$
    \bm{y}(s,\bm{z})  \triangleq \bm{y}^0(s) + \sum_{i \in [I_z]} \bm{y}^i(s) z_i.
    $$ 
    其中，系数$\bm{y}^0(s),\dots,\bm{y}^{I_z}(s)$是最终模型的实际决策变量。
    
    定义线性映射
    $$
    \left\{
    \begin{array}{rcl}
    \bm{a}_m(s,\bm{z}) &\triangleq& \bm{a}_{ms}^0 + \sum_{i \in [I_z]} \bm{a}_{ms}^i z_i \\
    \bm{b}_m(s,\bm{z}) &\triangleq& \bm{b}_{ms}^0 + \sum_{i \in [I_z]} \bm{b}_{ms}^i z_i \\
    \bm{c}_m(s) &\triangleq&  \bm{c}_{ms} \\
    d_m(s,\bm{z}) &\triangleq& d_{ms}^0 + \sum_{i \in [I_z]} d_{ms}^i z_i
    \end{array}\
    \right. ~~~\forall m \in [M] \cup \{0\}.
    $$
    其中，参数维度如下
    $$ 
    \bm{a}_{ms}^i \in \mathbb{R}^{J_w}, \bm{b}_{ms}^i \in \mathbb{R}^{J_x}, \bm{c}_{ms} \in \mathbb{R}^{J_y},  d_{ms}^i \in \mathbb{R} ~~~\forall i \in [I_z] \cup \{0\}, ~s \in [S].
    $$
    
    RSO模型的目标函数取分布集合$\mathcal{F}$（稍后介绍）下的最坏期望
    $$
    \sup_{\mathbb{P} \in \mathcal{F}} \ep{\bm{a}^\prime_0(\s,\bmt{z})\bm{w} + \bm{b}^\prime_0(\s,\bmt{z})\bm{x}(\s) + \bm{c}^\prime_0(\s)\bm{y}(\s,\bmt{z}) + d_0(\s,\bmt{z})}.
    $$
    
    RSO模型主要包含两类约束。第一类“硬”线性约束($m \in \mathcal{M}_1$)为一般鲁棒约束，需要在随机变量任意可能的取值下均满足：
    $$
    \bm{a}^\prime_m(s,\bm{z})\bm{w} + \bm{b}^\prime_m(s,\bm{z})\bm{x}(s) + \bm{c}^\prime_m(s)\bm{y}(s,\bm{z}) + d_m(s,\bm{z}) \leq 0 ~~~\forall \bm{z} \in  \mathcal{Z}_s, ~s \in [S].
    $$
    第二类“软”线性约束($m \in \mathcal{M}_2$)与目标函数类似，考虑分布集合$\mathcal{F}$下的最坏期望，并要求该最坏期望不为正：
    $$
    \sup_{\mathbb{P} \in \mathcal{F}} \ep{\bm{a}^\prime_m(\s,\bmt{z})\bm{w} + \bm{b}^\prime_m(\s,\bmt{z})\bm{x}(\s) + \bm{c}^\prime_m(\s)\bm{y}(\s,\bmt{z}) + d_m(\s,\bmt{z})} \leq 0 ~~~\forall m \in \mathcal{M}_2.
    $$
    
    除以上两类约束之外，在离散随机变量的不同取值下，RSO还包含非线性约束（如凸约束，整数约束等）
    $$
    \bm{r}(s) \triangleq \left(\bm{w},\bm{x}(s),\bm{y}^0(s),\dots,\bm{y}^{I_z}(s) \right) \in \mathcal{X}_s ~~~\forall s \in [S],
    $$ 
    
    
    \subsubsection*{事件式近似法则}
    记离散随机变量$\tilde{s}$的取值范围为$[S]$。特别地，离散随机变量$\tilde{s}$每一个取值$s$对应一个情景$s$。定义由情景组成的一个非空集合为一个事件$\mathcal{E} \subseteq [S]$。如此，全部情景的一个划分（partition?）定义了一个相互独立（mutually exclusive）又完全穷尽（collectively exhaustive）的MECE事件集合，记为$\mathcal{C}$。相应地，满足$\mathcal{H}_{\mathcal{C}}(s) = \mathcal{E}$ 函数$\mathcal{H}_{\mathcal{C}}:[S] \mapsto \mathcal{C}$确定了情景$s$在一个MECE事件集合中唯一所属的事件$\mathcal{E}$。
    
    给定一个MECE事件集合，事件式静态近似法则定义如下
    $$
    \mathcal{A}\left(\mathcal{C}\right) 
    \triangleq \left\{x : [S] \mapsto \mathbb{R} ~\left|~ 
    \begin{array}{l}  
    x(s) =  x^\mathcal{E}, ~\mathcal{E} = \mathcal{H}_\mathcal{C}(s) \\
    \mbox{for some}~ x^\mathcal{E} \in \mathbb{R} 
    \end{array}\right. \right\};
    $$ 
    亦即，不同事件下，静态决策不同。
    
    类似地，事件式线性近似法则定义如下
    $$
    \bar{\mathcal{A}}\left(\mathcal{C}, \mathcal{I}\right) \triangleq \left\{ y : [S]  \times \mathbb{R}^{I_z}  \mapsto \mathbb{R} ~\left|~ 
    \begin{array}{l}  
    y(s,\bm{z}) = 
    \displaystyle  y^0(s) + \sum_{i \in \mathcal{I}} y^i(s) z_i  \\
    \mbox{for some}~ y^0, y^i \in \mathcal{A}(\mathcal{C}), i \in \mathcal I
    \end{array}\right. \right\}
    $$  
    其中，信息集合$\mathcal I \subseteq [I_z]$为连续随机变量$\bmt{z}$的部分索引（components?），声明了连续随机变量$\bmt{z}$中，事件式线性近似法则所能线性依赖的成分。事件式线性近似法则声明了在不同事件下，动态决策不同，并且动态决策为连续随机变量$\bmt{z}$的线性函数。
    
    
    基于事件式近似法则，完整的RSO模型如下
    $$
    \begin{array}{cll}
    \min &\displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \ep{\bm{a}^\prime_0(\s,\bmt{z})\bm{w} + \bm{b}^\prime_0(\s,\bmt{z})\bm{x}(\s) + \bm{c}^\prime_0(\s)\bm{y}(\s,\bmt{z}) + d_0(\s,\bmt{z})} \\
    {\rm s.t.} &
    \bm{a}^\prime_m(s,\bm{z})\bm{w} + \bm{b}^\prime_m(s,\bm{z})\bm{x}(s) + \bm{c}^\prime_m(s)\bm{y}(s,\bm{z}) + d_m(s,\bm{z}) \leq 0 &~\forall \bm{z} \in  \mathcal{Z}_s, ~s \in [S], ~m \in \mathcal{M}_1 \\
    & \displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \ep{\bm{a}^\prime_m(\s,\bmt{z})\bm{w} + \bm{b}^\prime_m(\s,\bmt{z})\bm{x}(\s) + \bm{c}^\prime_m(\s)\bm{y}(\s,\bmt{z}) + d_m(\s,\bmt{z})} \leq 0 &~\forall m \in \mathcal{M}_2 \\
    &\left(\bm{w},\bm{x}(s),\bm{y}^0(s),\dots,\bm{y}^{I_z}(s) \right) \in \mathcal{X}_s &~\forall s \in [S]\\
    & x_j \in \mathcal{A}(\mathcal{C}^j_x) &~\forall j \in [J_x] \\
    & y_j \in \bar{\mathcal{A}}(\mathcal{C}^j_y, \mathcal{I}^j_y) &~\forall j \in [J_y]. 
    \end{array} 
    $$
    其中，$\mathcal{C}^j_x, j \in [J_x]$， $\mathcal{C}^j_y, j \in [J_y]$为MECE事件集合, $\mathcal{I}^j_y, j \in [J_y]$为信息集合。
    
    \subsubsection*{事件式分布模糊集}
    事件式分布模糊集刻画了连续随机变量$\bmt{z}$和离散随机变量$\tilde{s}$的联合分布的分布性质，包含了联合分布的分布信息。事件式分布模糊集取如下一般形式
    $$
    \label{eventwise_as}
    \mathcal{F} = \left\{\mathbb{P} \in \mathcal{P}_0\left(\mathbb{R}^{I_z} \times [S]\right) ~\left\vert~
    \begin{array}{ll}
    (\bmt{z},\s) \sim \mathbb{P}\\
    \ep{\bmt{z} \mid \s \in \mathcal{E}_k} \in \mathcal{Q}_k &~\forall k \in [K] \\
    \pp{\bmt{z} \in \mathcal{Z}_s \mid \s = s}  = 1 &~\forall s \in [S]  \\
    \pp{\s = s}  = p_s &~\forall s \in [S]  \\
    \mbox{for some } \bm{p} \in \mathcal{P}  
    \end{array}
    \right.
    \right\}
    $$
    其中，$\mathcal{E}_k, k \in [K]$为不同事件（注意，这些事件不需要组成MECE事件集合），$\mathcal{Z}_s, s \in [S]$, $\mathcal{Q}_k, k \in [K]$, 和$\mathcal{P} \subseteq \{\bm{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$为封闭的凸集合。事件式分布模糊集声明了
    \begin{enumerate}[(1)]
    \item 不同事件（$\mathcal{E}_k$）下连续随机变量$\bmt{z}$的事件期望（即条件期望）。
    \item 不同情景（$s$）下连续随机变量$\bmt{z}$的支撑集合（即条件支撑集合）。
    \item 不同情景（$s$）发生的概率。
    \end{enumerate}
    不确定集合$\mathcal{Q}_k, k \in [K]$和$\mathcal{P} \subseteq \{\bm{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$分别允许条件信息（1）和（3）亦可以是不确定的。
    
    
    \cite{Chen_Sim_Xiong_2019} 证明了事件式分布模糊集有非常好的普适性。它可以描述随机优化中常用的确定的离散分布（deterministic discrete distribution），以及分布鲁棒优化中用到的不确定的离散分布（uncertain discrete distribution）, 确定的（或不确定的）混合分布（mixture distribution），基于矩信息的分布模糊集（moments ambiguity set），以及数据驱动下（1）基于机器学习聚类或分类算法的分布模糊集（K-means ambiguity set）与（2）基于Wasserstein距离的分布模糊集（Wasserstein ambiguity set）。
    
    \subsubsection*{经典鲁棒优化转化}
    给定情景$s$，RSO模型中目标函数和“软（硬）”约束实际上是决策变量和连续随机变量$\bmt{z}$的取值$\bm{z}$的双线性函数。因为，我们可以将它们方便地记为
    $$
    {\bm{a}^\prime_m(s,\bm{z})\bm{w} + \bm{b}^\prime_m(s,\bm{z})\bm{x}(s) + \bm{c}^\prime_m(s)\bm{y}(s,\bm{z}) + d_m(s,\bm{z})}   \triangleq \bm{r}^\prime(s)\bm{G}_m(s)\bm{z} + h_m(s) ~~~\forall m \in [M] \cup \{0\}.
    $$
    其中，$\bm{G}_m(s)  \in  \mathbb{R}^{J_r \times I_z}$和 $h_m(s) \in \mathbb{R}$为参数。这样的双线性函数在事件式分布模糊集下的最坏期望可以通过求解一个经典鲁棒优化模型得到。换句话说，RSO模型可以很方便地通过的配套建模工具包进行建模。目前，\cite{Chen_Sim_Xiong_2019}论文中所提到的建模工具包RSOME的MATLAB版本已经发布（\url{https://sites.google.com/view/rsome/home}）。读者可以下载进行测试，并通过用户手册中的实例学习RSO的应用场景。
    
    \begin{theorem}{模型等价转换}{thm:worst-case expectation}\label{thm:worst-case expectation}
    最坏期望
    $$
    \sup_{\mathbb{P} \in \mathcal{F}} \ep{\bm{r}^\prime(\s)\bm{G}_m(\s)\bmt{z} + h_m(\s) } 
    $$
    等于如下经典鲁棒优化模型的最优目标函数值
    $$
    \begin{array}{cll}
    \inf & \gamma \\
    {\rm s.t.} & \gamma \geq \bm{\alpha}^\prime\bm{p} + \displaystyle \sum_{k \in [K]} \bm{\beta}^\prime_k\bm{\mu}_k &~\forall \bm{p} \in \mathcal{P}, ~\dfrac{\bm{\mu}_k}{\sum_{s \in \mathcal{E}_k} p_s} \in \mathcal{Q}_k, ~k \in [K] \\ 
    & \alpha_s + \displaystyle \sum_{k \in \mathcal{K}_s} \bm{\beta}_k^\prime\bm{z}  \geq \bm{r}^\prime(s)\bm{G}_m(s)\bm{z} + h_m(s) &~\forall \bm{z} \in \mathcal{Z}_s, ~s \in [S] \\
    & \gamma \in \mathbb{R}, ~\bm{\alpha} \in \mathbb{R}^S, ~\bm{\beta}_k \in \mathbb{R}^{I_z} &~\forall k \in [K],
    \end{array}
    $$
    其中对每一个$s \in [S]$, $\mathcal{K}_s = \{k \in [K] \mid s \in \mathcal{E}_k\}$.
    \end{theorem}
\fi

\bibliographystyle{aer}
\bibliography{References_zhichen}